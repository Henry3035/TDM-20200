{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c709786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status code: 200\n",
      "Content length: 513 bytes\n",
      "\n",
      "First 500 characters of HTML:\n",
      "<!doctype html><html lang=\"en\"><head><title>Example Domain</title><meta name=\"viewport\" content=\"width=device-width, initial-scale=1\"><style>body{background:#eee;width:60vw;margin:15vh auto;font-family:system-ui,sans-serif}h1{font-size:1.5em}div{opacity:0.8}a:link,a:visited{color:#348}</style><body><div><h1>Example Domain</h1><p>This domain is for use in documentation examples without needing permission. Avoid use in operations.<p><a href=\"https://iana.org/domains/example\">Learn more</a></div></\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from lxml import html\n",
    "\n",
    "# Fetch a web page\n",
    "url = \"https://example.com\"\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful\n",
    "print(f\"Status code: {response.status_code}\")\n",
    "print(f\"Content length: {len(response.content)} bytes\")\n",
    "\n",
    "# The HTML content is in response.text\n",
    "print(\"\\nFirst 500 characters of HTML:\")\n",
    "print(response.text[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6992e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page title: Example Domain\n",
      "\n",
      "Paragraphs found: 1\n",
      "1. This domain is for use in documentation examples without needing permission. Avoid use in operations.\n",
      "\n",
      "Heading: Example Domain\n"
     ]
    }
   ],
   "source": [
    "# Parse the HTML content\n",
    "tree = html.fromstring(response.text)\n",
    "\n",
    "# Extract the title\n",
    "title = tree.xpath('//title/text()')\n",
    "print(f\"Page title: {title[0] if title else 'Not found'}\")\n",
    "\n",
    "# Extract all paragraph text\n",
    "paragraphs = tree.xpath('//p/text()')\n",
    "print(f\"\\nParagraphs found: {len(paragraphs)}\")\n",
    "for i, para in enumerate(paragraphs, 1):\n",
    "    print(f\"{i}. {para}\")\n",
    "\n",
    "# Extract the heading\n",
    "heading = tree.xpath('//h1/text()')\n",
    "print(f\"\\nHeading: {heading[0] if heading else 'Not found'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5edec96a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status code: 200\n",
      "Page Title: Example Domain\n",
      "H1 Heading: Example Domain\n",
      "Paragraph 1: This domain is for use in documentation examples without needing permission. Avoid use in operations.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from lxml import html\n",
    "\n",
    "# 1.1. fetch the HTML from example.com using requests.get().\n",
    "url = \"https://example.com\"\n",
    "response = requests.get(url)\n",
    "\n",
    "# 1.2. Check the status code to verify the request was successful.\n",
    "if response.status_code == 200:\n",
    "    print(f\"Status code: {response.status_code}\")\n",
    "    \n",
    "    # 1.3. Parse the HTML using lxml.html.fromstring()\n",
    "    tree = html.fromstring(response.text)\n",
    "\n",
    "    # 1.4. Extract and display the page title\n",
    "    page_title = tree.xpath('//title/text()')\n",
    "    title_text = page_title[0] if page_title else 'not found'\n",
    "    print(f\"Page Title: {title_text}\")\n",
    "\n",
    "    # 1.5. Extract and display all paragraph text and the <h1> heading text.\n",
    "    heading_h1 = tree.xpath('//h1/text()')\n",
    "    h1_text = heading_h1[0] if heading_h1 else 'Not found'\n",
    "    print(f\"H1 Heading: {h1_text}\")\n",
    "\n",
    "    paragraphs = tree.xpath('//p/text()')\n",
    "    for i, p_text in enumerate(paragraphs, 1):\n",
    "        print(f\"Paragraph {i}: {p_text.strip()}\")\n",
    "\n",
    "else:\n",
    "    print(f\"Error status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b29a55d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10 quote containers\n",
      "\n",
      "Quote 1:\n",
      "  Text: “The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”\n",
      "  Author: Albert Einstein\n",
      "  Tags: change, deep-thoughts, thinking, world\n",
      "\n",
      "Quote 2:\n",
      "  Text: “It is our choices, Harry, that show what we truly are, far more than our abilities.”\n",
      "  Author: J.K. Rowling\n",
      "  Tags: abilities, choices\n",
      "\n",
      "Quote 3:\n",
      "  Text: “There are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.”\n",
      "  Author: Albert Einstein\n",
      "  Tags: inspirational, life, live, miracle, miracles\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from lxml import html\n",
    "\n",
    "url = \"https://quotes.toscrape.com\"\n",
    "response = requests.get(url)\n",
    "tree = html.fromstring(response.text)\n",
    "\n",
    "# Find all quote containers (divs with class=\"quote\")\n",
    "# You can find this by inspecting the page!\n",
    "quote_containers = tree.xpath('//div[@class=\"quote\"]')\n",
    "\n",
    "print(f\"Found {len(quote_containers)} quote containers\\n\")\n",
    "\n",
    "# Extract data from each container\n",
    "for i, container in enumerate(quote_containers[:3], 1):  # First 3 quotes\n",
    "    # Extract quote text from within this container\n",
    "    quote_text = container.xpath('.//span[@class=\"text\"]/text()')[0]\n",
    "\n",
    "    # Extract author from within this container\n",
    "    author = container.xpath('.//small[@class=\"author\"]/text()')[0]\n",
    "\n",
    "    # Extract tags from within this container\n",
    "    tags = container.xpath('.//a[@class=\"tag\"]/text()')\n",
    "\n",
    "    print(f\"Quote {i}:\")\n",
    "    print(f\"  Text: {quote_text}\")\n",
    "    print(f\"  Author: {author}\")\n",
    "    print(f\"  Tags: {', '.join(tags)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f46edfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10  quote containers\n",
      "\n",
      "Quote 1:\n",
      "  Text: “The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”\n",
      "  Author: Albert Einstein\n",
      "  Tags: change, deep-thoughts, thinking, world\n",
      "------------------------------\n",
      "Quote 2:\n",
      "  Text: “It is our choices, Harry, that show what we truly are, far more than our abilities.”\n",
      "  Author: J.K. Rowling\n",
      "  Tags: abilities, choices\n",
      "------------------------------\n",
      "Quote 3:\n",
      "  Text: “There are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.”\n",
      "  Author: Albert Einstein\n",
      "  Tags: inspirational, life, live, miracle, miracles\n",
      "------------------------------\n",
      "Quote 4:\n",
      "  Text: “The person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.”\n",
      "  Author: Jane Austen\n",
      "  Tags: aliteracy, books, classic, humor\n",
      "------------------------------\n",
      "Quote 5:\n",
      "  Text: “Imperfection is beauty, madness is genius and it's better to be absolutely ridiculous than absolutely boring.”\n",
      "  Author: Marilyn Monroe\n",
      "  Tags: be-yourself, inspirational\n",
      "------------------------------\n",
      "Quote 6:\n",
      "  Text: “Try not to become a man of success. Rather become a man of value.”\n",
      "  Author: Albert Einstein\n",
      "  Tags: adulthood, success, value\n",
      "------------------------------\n",
      "Quote 7:\n",
      "  Text: “It is better to be hated for what you are than to be loved for what you are not.”\n",
      "  Author: André Gide\n",
      "  Tags: life, love\n",
      "------------------------------\n",
      "Quote 8:\n",
      "  Text: “I have not failed. I've just found 10,000 ways that won't work.”\n",
      "  Author: Thomas A. Edison\n",
      "  Tags: edison, failure, inspirational, paraphrased\n",
      "------------------------------\n",
      "Quote 9:\n",
      "  Text: “A woman is like a tea bag; you never know how strong it is until it's in hot water.”\n",
      "  Author: Eleanor Roosevelt\n",
      "  Tags: misattributed-eleanor-roosevelt\n",
      "------------------------------\n",
      "Quote 10:\n",
      "  Text: “A day without sunshine is like, you know, night.”\n",
      "  Author: Steve Martin\n",
      "  Tags: humor, obvious, simile\n",
      "------------------------------\n",
      "\n",
      "Next page found: /page/2/\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from lxml import html\n",
    "\n",
    "# 2.1 & 2.2: Identify the HTML structure of quote containers using inspect element.\n",
    "url = \"https://quotes.toscrape.com\"\n",
    "response = requests.get(url)\n",
    "\n",
    "tree = html.fromstring(response.text)\n",
    "\n",
    "# 2.3: Write code to extract quote text, author, and tags for each quote.\n",
    "quote_containers = tree.xpath('//div[@class=\"quote\"]')\n",
    "\n",
    "print(f\"Found {len(quote_containers)}  quote containers\\n\")\n",
    "\n",
    "for i, container in enumerate(quote_containers, 1):\n",
    "    text = container.xpath('.//span[@class=\"text\"]/text()')[0]\n",
    "    author = container.xpath('.//small[@class=\"author\"]/text()')[0]\n",
    "    tags = container.xpath('.//a[@class=\"tag\"]/text()')\n",
    "\n",
    "    print(f\"Quote {i}:\")\n",
    "    print(f\"  Text: {text}\")\n",
    "    print(f\"  Author: {author}\")\n",
    "    print(f\"  Tags: {', '.join(tags)}\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "# 2.4: Extract the \"Next\" link’s href attribute (if it exists).\n",
    "next_link = tree.xpath('//li[@class=\"next\"]/a/@href')\n",
    "\n",
    "if next_link:\n",
    "    print(f\"\\nNext page found: {next_link[0]}\")\n",
    "else:\n",
    "    print(\"\\nNo 'Next' link found on this page.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3752ab7c",
   "metadata": {},
   "source": [
    "2.5 I used inspect -> Elements to see the html files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee256383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully fetched the page!\n",
      "\n",
      "Found 68 links on the page\n",
      "1. https://the-examples-book.com\n",
      "2. crp/\n",
      "3. meeting-etiquette/\n",
      "4. personal/\n",
      "5. projects/\n",
      "6. seminar-ta/home\n",
      "7. internal/main/introduction\n",
      "8. workshops/\n",
      "9. ./\n",
      "10. tools/\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from lxml import html\n",
    "\n",
    "url = \"https://the-examples-book.com\"\n",
    "response = requests.get(url)\n",
    "\n",
    "# Always check the status code first\n",
    "if response.status_code == 200:\n",
    "    print(\"Successfully fetched the page!\")\n",
    "    tree = html.fromstring(response.text)\n",
    "\n",
    "    # Use inspect element to find what you want to extract\n",
    "    # For example, let's find all links on the page\n",
    "    links = tree.xpath('//a/@href')\n",
    "    print(f\"\\nFound {len(links)} links on the page\")\n",
    "\n",
    "    # Show first 10 links\n",
    "    for i, link in enumerate(links[:10], 1):\n",
    "        print(f\"{i}. {link}\")\n",
    "else:\n",
    "    print(f\"Error: Status code {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78b96701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully fetched the page!\n",
      "Found 6 heading\n",
      "Heading 1: The Examples Book\n",
      "Heading 2: Overview\n",
      "Heading 3: Core Topics\n",
      "Heading 4: Course Links\n",
      "Heading 5: Grant Awarded Programs\n",
      "Found 68 link\n",
      "Link 1: https://the-examples-book.com\n",
      "Link 2: crp/\n",
      "Link 3: meeting-etiquette/\n",
      "Link 4: personal/\n",
      "Link 5: projects/\n",
      "Link 6: seminar-ta/home\n",
      "Link 7: internal/main/introduction\n",
      "Link 8: workshops/\n",
      "Link 9: ./\n",
      "Link 10: tools/\n",
      "Found 28paragraphs\n",
      "1:Welcome to The All New Examples Book! This book contains a collection of information and examples th\n",
      "2:seminar at\n",
      "3:. The Examples Book is open to anyone. Even if you aren’t a student at Purdue we hope you find helpf\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from lxml import html\n",
    "\n",
    "# 3.1 & 3.2:  Identify at least 3 different types of elements you want to extract.\n",
    "\n",
    "url = \"https://the-examples-book.com\"\n",
    "response = requests.get(url)\n",
    "\n",
    "# 3.3: Write code to fetch and parse the page.\n",
    "if response.status_code == 200:\n",
    "    print(\"Successfully fetched the page!\")\n",
    "    tree = html.fromstring(response.text)\n",
    "    # 3.4 & 3.5: Extract the information you identified and Display the results in a readable format.\n",
    "    headings = tree.xpath('//h1/text() | //h2/text()')\n",
    "    print(f\"Found {len(headings)} heading\")\n",
    "    for i, head in enumerate(headings[:5], 1):\n",
    "        print(f\"Heading {i}: {head.strip()}\")\n",
    "\n",
    "    links = tree.xpath('//a/@href')\n",
    "    print(f\"Found {len(links)} link\")\n",
    "    for i, link in enumerate(links[:10], 1):\n",
    "        print(f\"Link {i}: {link}\")\n",
    "\n",
    "    paragraphs = tree.xpath('//p/text()')\n",
    "    print(f\"Found {len(paragraphs)}paragraphs\")\n",
    "    for i, para in enumerate(paragraphs[:3], 1): \n",
    "        if para.strip():\n",
    "            print(f\"{i}:{para.strip()[:100]}\") \n",
    "\n",
    "else:\n",
    "    print(f\"Error: Status code {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e7d516d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 1...\n",
      "Scraping page 2...\n",
      "Scraping page 3...\n",
      "Scraping page 4...\n",
      "Scraping page 5...\n",
      "Scraping page 6...\n",
      "Scraping page 7...\n",
      "Scraping page 8...\n",
      "Scraping page 9...\n",
      "Scraping page 10...\n",
      "No more pages!\n",
      "\n",
      "Total quotes scraped: 100\n",
      "\n",
      "First 3 quotes:\n",
      "1. “The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.” - Albert Einstein - Tags: change, deep-thoughts, thinking, world\n",
      "2. “It is our choices, Harry, that show what we truly are, far more than our abilities.” - J.K. Rowling - Tags: abilities, choices\n",
      "3. “There are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.” - Albert Einstein - Tags: inspirational, life, live, miracle, miracles\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from lxml import html\n",
    "import time\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "base_url = \"https://quotes.toscrape.com\"\n",
    "current_url = base_url\n",
    "all_quotes = []\n",
    "page_num = 1\n",
    "\n",
    "while True:\n",
    "    print(f\"Scraping page {page_num}...\")\n",
    "    response = requests.get(current_url)\n",
    "    tree = html.fromstring(response.text)\n",
    "\n",
    "    # Extract quotes from current page\n",
    "    quote_containers = tree.xpath('//div[@class=\"quote\"]')\n",
    "    for container in quote_containers:\n",
    "        text = container.xpath('.//span[@class=\"text\"]/text()')[0]\n",
    "        author = container.xpath('.//small[@class=\"author\"]/text()')[0]\n",
    "        tags = container.xpath('.//a[@class=\"tag\"]/text()')\n",
    "        all_quotes.append({\"text\": text, \"author\": author, \"tags\": tags})\n",
    "\n",
    "    # Check for \"Next\" button using inspect element to find the selector\n",
    "    next_button = tree.xpath('//li[@class=\"next\"]/a/@href')\n",
    "\n",
    "    if next_button:\n",
    "        # Construct full URL (handling relative URLs)\n",
    "        next_url = next_button[0]\n",
    "        # Use urljoin to properly combine URLs\n",
    "        current_url = urljoin(base_url, next_url)\n",
    "        page_num += 1\n",
    "        time.sleep(1)  # Be polite - wait between requests\n",
    "    else:\n",
    "        print(\"No more pages!\")\n",
    "        break\n",
    "\n",
    "print(f\"\\nTotal quotes scraped: {len(all_quotes)}\")\n",
    "print(f\"\\nFirst 3 quotes:\")\n",
    "for i, quote in enumerate(all_quotes[:3], 1):\n",
    "    print(f\"{i}. {quote['text']} - {quote['author']} - Tags: {', '.join(quote['tags'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "29c16147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 1...\n",
      "Scraping page 2...\n",
      "Scraping page 3...\n",
      "Scraping page 4...\n",
      "Scraping page 5...\n",
      "Scraping page 6...\n",
      "Scraping page 7...\n",
      "Scraping page 8...\n",
      "Scraping page 9...\n",
      "Scraping page 10...\n",
      "No more pages!\n",
      "\n",
      "Total quotes scraped: 100\n",
      "\n",
      "First 3 quotes:\n",
      "1. “The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.” - Albert Einstein - Tags: change, deep-thoughts, thinking, world\n",
      "2. “It is our choices, Harry, that show what we truly are, far more than our abilities.” - J.K. Rowling - Tags: abilities, choices\n",
      "3. “There are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.” - Albert Einstein - Tags: inspirational, life, live, miracle, miracles\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from lxml import html\n",
    "import time\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "base_url = \"https://quotes.toscrape.com\"\n",
    "current_url = base_url\n",
    "all_quotes = []\n",
    "page_num = 1\n",
    "\n",
    "while True:\n",
    "    print(f\"Scraping page {page_num}...\")\n",
    "    response = requests.get(current_url)\n",
    "    tree = html.fromstring(response.text)\n",
    "\n",
    "    # 4.3. Extract quote text, author, and tags from each page.\n",
    "    quote_containers = tree.xpath('//div[@class=\"quote\"]')\n",
    "    for container in quote_containers:\n",
    "        text = container.xpath('.//span[@class=\"text\"]/text()')[0]\n",
    "        author = container.xpath('.//small[@class=\"author\"]/text()')[0]\n",
    "        tags = container.xpath('.//a[@class=\"tag\"]/text()')\n",
    "        \n",
    "        # 4.4. Store all data in a structured format (list of dictionaries).\n",
    "        all_quotes.append({\"text\": text, \"author\": author, \"tags\": tags})\n",
    "\n",
    "    # 4.1. Write code to scrape all pages from quotes.toscrape.com\n",
    "    next_button = tree.xpath('//li[@class=\"next\"]/a/@href')\n",
    "    # 4.2. Handle pagination by following \"Next\" links (use inspect element to find the selector).\n",
    "    if next_button:\n",
    "        next_url = next_button[0]\n",
    "        current_url = urljoin(base_url, next_url)\n",
    "        page_num += 1\n",
    "        time.sleep(1) \n",
    "    else:\n",
    "        print(\"No more pages!\")\n",
    "        break\n",
    "\n",
    "# 4.5. Print the total number of quotes scraped and display a few examples.\n",
    "print(f\"\\nTotal quotes scraped: {len(all_quotes)}\")\n",
    "print(f\"\\nFirst 3 quotes:\")\n",
    "for i, quote in enumerate(all_quotes[:3], 1):\n",
    "    print(f\"{i}. {quote['text']} - {quote['author']} - Tags: {', '.join(quote['tags'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "11909fe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author name to profile URL mapping:\n",
      "(about): https://quotes.toscrape.com/author/Steve-Martin\n",
      "\n",
      "Found 40 tag links\n",
      "\n",
      "First 10 tags:\n",
      "1. change -> https://quotes.toscrape.com/tag/change/page/1/\n",
      "2. deep-thoughts -> https://quotes.toscrape.com/tag/deep-thoughts/page/1/\n",
      "3. thinking -> https://quotes.toscrape.com/tag/thinking/page/1/\n",
      "4. world -> https://quotes.toscrape.com/tag/world/page/1/\n",
      "5. abilities -> https://quotes.toscrape.com/tag/abilities/page/1/\n",
      "6. choices -> https://quotes.toscrape.com/tag/choices/page/1/\n",
      "7. inspirational -> https://quotes.toscrape.com/tag/inspirational/page/1/\n",
      "8. life -> https://quotes.toscrape.com/tag/life/page/1/\n",
      "9. live -> https://quotes.toscrape.com/tag/live/page/1/\n",
      "10. miracle -> https://quotes.toscrape.com/tag/miracle/page/1/\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from lxml import html\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "url = \"https://quotes.toscrape.com\"\n",
    "response = requests.get(url)\n",
    "tree = html.fromstring(response.text)\n",
    "\n",
    "# Extract author profile links\n",
    "author_link_elements = tree.xpath('//a[contains(@href, \"/author/\")]')\n",
    "author_dict = {}\n",
    "\n",
    "for elem in author_link_elements:\n",
    "    author_name = elem.text\n",
    "    author_href = elem.get('href')\n",
    "    # Convert relative URL to absolute\n",
    "    full_url = urljoin(url, author_href)\n",
    "    author_dict[author_name] = full_url\n",
    "\n",
    "print(\"Author name to profile URL mapping:\")\n",
    "for name, profile_url in list(author_dict.items())[:5]:\n",
    "    print(f\"{name}: {profile_url}\")\n",
    "\n",
    "# Extract tag links\n",
    "tag_elements = tree.xpath('//a[@class=\"tag\"]')\n",
    "print(f\"\\nFound {len(tag_elements)} tag links\")\n",
    "print(\"\\nFirst 10 tags:\")\n",
    "for i, tag_elem in enumerate(tag_elements[:10], 1):\n",
    "    tag_text = tag_elem.text\n",
    "    tag_href = tag_elem.get('href')\n",
    "    tag_url = urljoin(url, tag_href)\n",
    "    print(f\"{i}. {tag_text} -> {tag_url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2d75dfea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Author Profile Mapping (First 5) ---\n",
      "(about): https://quotes.toscrape.com/author/Steve-Martin\n",
      "\n",
      "--- Unique Tags Found (30) ---\n",
      "abilities, adulthood, aliteracy, be-yourself, books, change, choices, classic, deep-thoughts, edison, failure, friends, friendship, humor, inspirational, life, live, love, miracle, miracles, misattributed-eleanor-roosevelt, obvious, paraphrased, reading, simile, success, thinking, truth, value, world\n",
      "\n",
      "--- Tag Links (First 10) ---\n",
      "1. change -> https://quotes.toscrape.com/tag/change/page/1/\n",
      "2. deep-thoughts -> https://quotes.toscrape.com/tag/deep-thoughts/page/1/\n",
      "3. thinking -> https://quotes.toscrape.com/tag/thinking/page/1/\n",
      "4. world -> https://quotes.toscrape.com/tag/world/page/1/\n",
      "5. abilities -> https://quotes.toscrape.com/tag/abilities/page/1/\n",
      "6. choices -> https://quotes.toscrape.com/tag/choices/page/1/\n",
      "7. inspirational -> https://quotes.toscrape.com/tag/inspirational/page/1/\n",
      "8. life -> https://quotes.toscrape.com/tag/life/page/1/\n",
      "9. live -> https://quotes.toscrape.com/tag/live/page/1/\n",
      "10. miracle -> https://quotes.toscrape.com/tag/miracle/page/1/\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from lxml import html\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "url = \"https://quotes.toscrape.com\"\n",
    "response = requests.get(url)\n",
    "tree = html.fromstring(response.text)\n",
    "\n",
    "# 5.1. Extract all author profile links from the page.\n",
    "author_link_elements = tree.xpath('//a[contains(@href, \"/author/\")]')\n",
    "# 5.3. Create a dictionary mapping author names to their profile URLs (use absolute URLs).\n",
    "author_dict = {}\n",
    "\n",
    "for elem in author_link_elements:\n",
    "    author_name = elem.text.strip()\n",
    "    author_href = elem.get('href')\n",
    "    full_url = urljoin(url, author_href)\n",
    "    author_dict[author_name] = full_url\n",
    "\n",
    "# 5.2. Extract tag names and their corresponding links.\n",
    "tag_elements = tree.xpath('//a[@class=\"tag\"]')\n",
    "tag_data = []\n",
    "for tag_elem in tag_elements:\n",
    "    name = tag_elem.text\n",
    "    link = urljoin(url, tag_elem.get('href'))\n",
    "    tag_data.append((name, link))\n",
    "\n",
    "# 5.4. Create a list of all unique tags.\n",
    "unique_tags = sorted(list(set([tag[0] for tag in tag_data])))\n",
    "\n",
    "# 5.5. Display the results in a clear format.\n",
    "print(\"--- Author Profile Mapping (First 5) ---\")\n",
    "for name, profile_url in list(author_dict.items())[:5]:\n",
    "    print(f\"{name}: {profile_url}\")\n",
    "\n",
    "print(f\"\\n--- Unique Tags Found ({len(unique_tags)}) ---\")\n",
    "print(\", \".join(unique_tags))\n",
    "\n",
    "print(\"\\n--- Tag Links (First 10) ---\")\n",
    "for i, (name, link) in enumerate(tag_data[:10], 1):\n",
    "    print(f\"{i}. {name} -> {link}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebf72cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
